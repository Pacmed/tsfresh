{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pylab as plt\n",
    "plt.style.use('seaborn')\n",
    "import seaborn as sns\n",
    "\n",
    "from tsfresh import extract_features\n",
    "from tsfresh.utilities.dataframe_functions import make_forecasting_frame\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from tsfresh.utilities.dataframe_functions import impute\n",
    "\n",
    "# Fix needed to pandas datareader\n",
    "pd.core.common.is_list_like = pd.api.types.is_list_like\n",
    "import pandas_datareader.data as web\n",
    "import datetime\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collect the data for the google stock "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = datetime.datetime(2016, 1, 1)\n",
    "end = datetime.datetime(2017, 1, 1)\n",
    "\n",
    "# Need to use iex instead of google\n",
    "x = web.DataReader(\"F\", 'iex', start, end)\n",
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.drop(\"volume\", axis=1).plot(figsize=(15, 6))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, we loaded the google stock for one year. Now, we want to predict the High column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create forecasting frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_shift, y = make_forecasting_frame(x[\"high\"], kind=\"price\", max_timeshift=20, rolling_direction=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_shift.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_shift.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`df_shift` is ready to be passed into the feature extraction process in tsfresh "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "X = extract_features(df_shift, column_id=\"id\", column_sort=\"time\", column_value=\"value\", impute_function=impute,\n",
    "                     show_warnings=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop constant features\n",
    "print(X.shape)\n",
    "X = X.loc[:, X.apply(pd.Series.nunique) != 1] \n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add last value as feature\n",
    "X[\"feature_last_value\"] = y.shift(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop first line\n",
    "X = X.iloc[1:, ]\n",
    "y = y.iloc[1: ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Fit Adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada = AdaBoostRegressor(n_estimators=10)\n",
    "y_pred = [np.NaN] * len(y)\n",
    "\n",
    "isp = 100   # index of where to start the predictions\n",
    "assert isp > 0\n",
    "\n",
    "for i in tqdm(range(isp, len(y))):\n",
    "    \n",
    "    ada.fit(X.iloc[:i], y[:i])\n",
    "    y_pred[i] = ada.predict(X.iloc[i, :].values.reshape((1, -1)))[0]\n",
    "    \n",
    "y_pred = pd.Series(data=y_pred, index=y.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe of predictions and true values\n",
    "ys = pd.concat([y_pred, y], axis = 1).rename(columns = {0: 'pred', 'value': 'true'})\n",
    "\n",
    "# Convert index to a datetime\n",
    "ys.index = pd.to_datetime(ys.index)\n",
    "ys.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ys.plot(figsize=(15, 8))\n",
    "plt.title('Predicted and True Price')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks not too bad. The green curve is the output of the AdaBoost Regressor, the blue curve is the true High value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will also inspect last value before the prediction as a benchmark tool, denoted by y-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create column of previous price\n",
    "ys['y-1'] = ys['true'].shift(1)\n",
    "ys[['y-1', 'true']].plot(figsize = (15, 8))\n",
    "plt.title('Benchmark Prediction and True Price')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"MAE y-1: \\t{}\".format(np.mean(np.abs(np.diff(y))[isp-1:] )))\n",
    "print(\"MAE ada: \\t{}\".format(np.mean(np.abs(y_pred - y)[isp:])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, we are not yet beating the y-1 benchmark, so we need to invest more time into building dedicated features or use a better model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also inspect the relevance of the extracted features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = pd.Series(index=X.columns, data=ada.feature_importances_)\n",
    "importances.sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, the minumum value \"feature__maximum\" during the last 10 values had the highest importance to predict the next value of the `High` column"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
